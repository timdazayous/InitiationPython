{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71c872c",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "**Exercice 1 - Chargement de données :**\n",
    "* Téléchargez le fichier CSV \"titanic.csv\" à partir du lien suivant : https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
    "* Utilisez Pandas pour charger ce fichier dans un DataFrame nommé \"titanic_df\".\n",
    "* Affichez les 5 premières lignes du DataFrame pour inspecter les données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faae9ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Téléchargement du fichier titanic.csv depuis un url\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "\n",
    "# Chargement du fichier dans un DataFrame titanic_df\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Affichage des 5 premieres lignes de titanic.csv\n",
    "print(titanic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655f3a5",
   "metadata": {},
   "source": [
    "**Exercice 2 - Exploration des données :**\n",
    "* Trouvez le nombre total de passagers dans le Titanic.\n",
    "* Déterminez le pourcentage de passagers qui ont survécu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe6c83da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de survivant est de 38%\n"
     ]
    }
   ],
   "source": [
    "# On recupere le nombre d'élément contenu dans titanic_df len ignore l'entete \n",
    "nombre_de_passagers = len(titanic_df)\n",
    "\n",
    "# Calcul du nombre de survivants\n",
    "nombre_survivants = (titanic_df[\"Survived\"] == 1).sum() # nombre_survivants = titanic_df[\"Survived\"].sum() possible aussi car les valeurs sont des 0 ou des 1 (dans python 0 == False et 1 == True)\n",
    "\n",
    "# Calcul du pourcentage de survivants\n",
    "pourcentage_survivants = (nombre_survivants/nombre_de_passagers)*100\n",
    "\n",
    "print(f\"Le pourcentage de survivant est de {round(pourcentage_survivants)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e3d2c",
   "metadata": {},
   "source": [
    "**Exercice 3 - Analyse des âges :**\n",
    "* Calculez l'âge moyen des passagers.\n",
    "* Trouvez l'âge le plus fréquent des passagers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c015cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne d'age de 30 ans.\n",
      "Moyenne d'age de 30 ans.\n",
      "L'age le plus fréquent etait de 24 ans.\n"
     ]
    }
   ],
   "source": [
    "# Methode en dur\n",
    "# On fait un tableau des ages des passagers\n",
    "tab_ages = titanic_df[\"Age\"].dropna() # dropna() permet de supprimer les cases vides et ne pas avoir de decalage avec le len() ou le sum()\n",
    "# Calcul de la somme des ages\n",
    "somme_age = tab_ages.sum()\n",
    "# Nombre de passagers ayant un age renseigné avec len \n",
    "nombre_de_passagers = len(tab_ages)\n",
    "\n",
    "# Calcul moyenne d'age \n",
    "moyenne_ages = somme_age/nombre_de_passagers\n",
    "\n",
    "print(f\"Moyenne d'age de {round(moyenne_ages)} ans.\")\n",
    "\n",
    "# pd.dataFrame.mean() calculer automatiquement le moyenne de toutes les valeurs de age sans compter les cases vides\n",
    "age_moyen = titanic_df[\"Age\"].mean()\n",
    "\n",
    "print(f\"Moyenne d'age de {round(age_moyen)} ans.\")\n",
    "\n",
    "# pd.dataFrame.mode() renvoi un tableau de ou des valeurs les plus presentes\n",
    "tab_age_le_plus_frequent = tab_ages.mode()\n",
    "\n",
    "# On recupere le premier element du tab_age_le_plus_frequent il contient la valeur avce le plus d'iterations dans le csv\n",
    "age_le_plus_frequent = tab_age_le_plus_frequent.values[0]\n",
    "\n",
    "print(f\"L'age le plus fréquent etait de {round(age_le_plus_frequent)} ans.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c28f6ff",
   "metadata": {},
   "source": [
    "**Exercice 4 - Filtrage des données :**\n",
    "* Créez un nouveau DataFrame \"survived_df\" contenant uniquement les passagers qui ont survécu.\n",
    "* Créez un nouveau DataFrame \"non_survived_df\" contenant uniquement les passagers qui n'ont pas survécu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb35507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n",
      "   PassengerId  Survived  Pclass                            Name   Sex   Age  \\\n",
      "0            1         0       3         Braund, Mr. Owen Harris  male  22.0   \n",
      "4            5         0       3        Allen, Mr. William Henry  male  35.0   \n",
      "5            6         0       3                Moran, Mr. James  male   NaN   \n",
      "6            7         0       1         McCarthy, Mr. Timothy J  male  54.0   \n",
      "7            8         0       3  Palsson, Master. Gosta Leonard  male   2.0   \n",
      "\n",
      "   SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
      "0      1      0  A/5 21171   7.2500   NaN        S  \n",
      "4      0      0     373450   8.0500   NaN        S  \n",
      "5      0      0     330877   8.4583   NaN        Q  \n",
      "6      0      0      17463  51.8625   E46        S  \n",
      "7      3      1     349909  21.0750   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Création de dataFrame des passagers ayant survecus et de ceux ne l'ayant pas \n",
    "survived_df = titanic_df[titanic_df[\"Survived\"] == 1]\n",
    "non_survived_df = titanic_df[titanic_df[\"Survived\"] == 0]\n",
    "\n",
    "print(survived_df.head())\n",
    "print(non_survived_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9662edd",
   "metadata": {},
   "source": [
    "**Exercice 5 - Statistiques des tarifs :**\n",
    "* Trouvez le tarif minimum, maximum, moyen et médian payé par les passagers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fead7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarif minimum de: 0.0 euros\n",
      "Tarif maximum de: 512.3292 euros\n",
      "Tarif moyen de: 32.204207968574636 euros\n",
      "Tarif median de: 14.4542 euros\n"
     ]
    }
   ],
   "source": [
    "# On créer un tableau contenant toutes les valeurs de Fare sans les cellules vides grace a dropna()\n",
    "tab_fare = titanic_df[\"Fare\"].dropna()\n",
    "\n",
    "# Calculs des tarifs min, max, moyen, et median\n",
    "min_fare = tab_fare.min()\n",
    "max_fare = tab_fare.max()\n",
    "moyenne_fare = tab_fare.mean()\n",
    "median_fare = tab_fare.median()\n",
    "\n",
    "print(f\"Tarif minimum de: {min_fare} euros\")\n",
    "print(f\"Tarif maximum de: {max_fare} euros\")\n",
    "print(f\"Tarif moyen de: {moyenne_fare} euros\")\n",
    "print(f\"Tarif median de: {median_fare} euros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10246ba",
   "metadata": {},
   "source": [
    "**Exercice 6 - Traitement des valeurs manquantes :**\n",
    "* Téléchargez le fichier CSV \"sales_data.csv\" à partir du lien suivant : https://github.com/ine-rmotr-curriculum/FreeCodeCamp-Pandas-Real-Life-Example/blob/master/data/sales_data.csv\n",
    "* Chargez le fichier dans un DataFrame nommé \"sales_df\".\n",
    "* Affichez le nombre de valeurs manquantes dans chaque colonne du DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb03204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                0\n",
      "Day                 0\n",
      "Month               0\n",
      "Year                0\n",
      "Customer_Age        0\n",
      "Age_Group           0\n",
      "Customer_Gender     0\n",
      "Country             0\n",
      "State               0\n",
      "Product_Category    0\n",
      "Sub_Category        0\n",
      "Product             0\n",
      "Order_Quantity      0\n",
      "Unit_Cost           0\n",
      "Unit_Price          0\n",
      "Profit              0\n",
      "Cost                0\n",
      "Revenue             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#url_2 = \"https://raw.githubusercontent.com/ine-rmotr-curriculum/FreeCodeCamp-Pandas-Real-Life-Example/refs/heads/master/data/sales_data.csv\"\n",
    "url_2 = \"https://raw.githubusercontent.com/ine-rmotr-curriculum/FreeCodeCamp-Pandas-Real-Life-Example/master/data/sales_data.csv\"\n",
    "\n",
    "sales_df = pd.read_csv(url_2)\n",
    "\n",
    "# Nombre de valeurs manquantes par colonne\n",
    "# .isnull() retourne un dataFrame de meme taille que saleds_df chaques cellules contient True si elle contient une valeur False sinon\n",
    "# True == 1 et False == 0 \n",
    "# .sum() va donc faire +0 si la cellule est remplie car isnull() sera faux donc == 0 et si la cellule est vide il prendra +1\n",
    "nombre_val_manquantes = sales_df.isnull().sum()\n",
    "\n",
    "print(nombre_val_manquantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3238e",
   "metadata": {},
   "source": [
    "**Exercice 7 - Suppression des doublons :**\n",
    "* Téléchargez le fichier CSV \"GlobalLandTemperaturesByMajorCity.csv\" à partir du lien suivant : https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data?select=GlobalLandTemperaturesByMajorCity.csv\n",
    "* Chargez le fichier dans un DataFrame nommé \"duplicate_df\".\n",
    "* Supprimez les lignes en double du DataFrame.\n",
    "* Afficher la taille des Dataframes avant et après\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373741ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille avant suppression des doublons : (8599212, 7)\n",
      "Taille aprés suppression des doublons (8599212, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url_3 = \"GlobalLandTemperaturesByCity.csv\"\n",
    "duplicate_df = pd.read_csv(url_3)\n",
    "\n",
    "print(\"Taille avant suppression des doublons :\", duplicate_df.shape)\n",
    "\n",
    "# Suppression des doublons\n",
    "duplicate_df = duplicate_df.drop_duplicates()\n",
    "print(\"Taille aprés suppression des doublons\", duplicate_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c787b2d",
   "metadata": {},
   "source": [
    "**Exercice 8 - Remplacement des valeurs incorrectes :**\n",
    "* Chargez le fichier dans un DataFrame nommé \"temperature_df\".\n",
    "* Remplacez les valeurs négatives dans la colonne \"AverageTemperature\" par la valeur absolue de ces valeurs.\n",
    "* Afficher le minimum avant et après\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a60a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature moyenne minimum avant remplacement : -42.70399999999999\n",
      "Temperature moyenne minimum apres remplacement : 0.0\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"GlobalLandTemperaturesByCity.csv\"\n",
    "temperature_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Afficher AverageTemperature minimum avant remplacement\n",
    "print(f\"Temperature moyenne minimum avant remplacement : {temperature_df['AverageTemperature'].min()}\")\n",
    "\n",
    "# Remplacement des valeurs negatives par leur valeur absolue\n",
    "temperature_df['AverageTemperature'] = temperature_df['AverageTemperature'].abs()\n",
    "\n",
    "# Affichage AverageTemperature apres rempalacement des valeurs negatives en valeurs absolues\n",
    "print(f\"Temperature moyenne minimum apres remplacement : {temperature_df['AverageTemperature'].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345b4ca",
   "metadata": {},
   "source": [
    "**Exercice 9 - Extraction de données :**\n",
    "* Téléchargez le fichier CSV \"email_jetable.csv\" à partir du lien suivant : https://sql.sh/ressources/sql-email-jetable/email_jetable.csv\n",
    "* Chargez le fichier dans un DataFrame nommé \"emails_df\".\n",
    "* Donnez un nom aux colonnes: [index, emails]\n",
    "* Créez une nouvelle colonne \"extension\" contenant uniquement l’extension du domaines des adresses e-mail (com, fr etc…).\n",
    "* Affichez les valeurs unique de la colonne “extension”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions uniques : ['com' 'net' 'org' 'to' 'de' 'cx' 'info' 'nf' 'in' 'it' 'br' 'tk' 'uk'\n",
      " 'biz' 'eu' 'cc' 'by' 'lv' 'dj' 'nu' 'id' 'ws' 'tc' 'us' 'at' 'me'\n",
      " 'gravel' 'la' 'ru' 'fr']\n"
     ]
    }
   ],
   "source": [
    "url_4 = \"https://sql.sh/ressources/sql-email-jetable/email_jetable.csv\"\n",
    "\n",
    "# La premiere ligne du csv n'est pas le nom des colonnes donc on precise header = none et ensuite on créer les noms de colonnes manuellement\n",
    "emails_df = pd.read_csv(url_4, header=None, names=['index', 'emails'])\n",
    "\n",
    "# On ajoute la colonne 'extension' contenant l'extension du domaine de l'adresse mail\n",
    "\n",
    "# .str permet d'appliquer des operations de string sur une colonne pandas\n",
    "# @[^.]+ : match le domaine après le @ jusqu’au dernier point\n",
    "# ([a-zA-Z]+) : capture l’extension (ex: com, fr)\n",
    "# $ : fin de chaîne\n",
    "# Prend en compte les sous domaines mais ne fonctionne pas bien s'il y a des valeurs nulles ou au mauvais format et donc ne retourne pas d'extensions uniques\n",
    "#emails_df['extension'] = emails_df[\"emails\"].str.extract(r'@[^.]+\\.([a-zA-Z]+)$')\n",
    "\n",
    "# Plus simple mais ne prend pas en compte les sous domaines (ex: .co.uk) decoupe chaque email en morceau utilisant '.' comme separateur puis on prend le dernier element\n",
    "emails_df['extension'] = emails_df['emails'].str.split('.').str[-1] \n",
    "\n",
    "# Afficher les extensions uniques \n",
    "extensions_uniques = emails_df['extension'].unique()\n",
    "\n",
    "print(\"Extensions uniques :\", extensions_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe1f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions uniques : []\n"
     ]
    }
   ],
   "source": [
    "# Tentative pour recuperer les sous domaines sil y en a avec aide de chatgpt mais non fructeuse\n",
    "url = \"https://sql.sh/ressources/sql-email-jetable/email_jetable.csv\"\n",
    "emails_df = pd.read_csv(url, header=None, names=['index', 'emails'])\n",
    "\n",
    "# Nettoyer les espaces et les valeurs vides\n",
    "emails_df['emails'] = emails_df['emails'].astype(str).str.strip()\n",
    "\n",
    "# Filtrer les emails valides (au moins un @ et un point après)\n",
    "valid_emails = emails_df['emails'].str.contains(r'@.*\\.', regex=True)\n",
    "emails_df = emails_df[valid_emails].copy()\n",
    "\n",
    "# Extraire la vraie extension complète (2 derniers morceaux si besoin)\n",
    "emails_df['extension'] = emails_df['emails'].str.split('.').apply(lambda x: '.'.join(x[-2:]) if len(x) >= 2 else x[-1])\n",
    "\n",
    "# Afficher les extensions uniques\n",
    "extensions_uniques = emails_df['extension'].unique()\n",
    "print(\"Extensions uniques :\", extensions_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85bd64",
   "metadata": {},
   "source": [
    "**Exercice 10 - Transformation de données :**\n",
    "* Téléchargez le fichier CSV \"student_grades.csv\" à partir du lien suivant : https://github.com/DeVerMyst/DEVIA2023/blob/master/data/student_grades.csv\n",
    "* Chargez le fichier dans un DataFrame nommé \"grades_df\".\n",
    "* Donnez un nom aux colonnes: ['ID','salle','note']\n",
    "* Ajoutez une colonne “note_dec” qui contient les notes de 0 à 17 (E- à A+) (de 0 à 14 surement une erreur dans l'énoncé)\n",
    "* Convertissez les notes pour qu’elles soient entre 0 et 20 en appliquant une fonction\n",
    "* Ajoutez une colonne \"result\" qui contiendra \"Réussite\" pour les étudiants ayant une note supérieure ou égale à 10, sinon \"Échec\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = \"student_grades.csv\"\n",
    "grades_df = pd.read_csv(path_csv, header=None, names=['ID', 'salle', 'note'])\n",
    "\n",
    "# Création d'un dictionnaire pour faire correspondre les notes alphabetiques avec les notes numeriques\n",
    "grade_to_num = {\n",
    "    'E-': 0, 'E': 1, 'E+': 2,\n",
    "    'D-': 3, 'D': 4, 'D+': 5,\n",
    "    'C-': 6, 'C': 7, 'C+': 8,\n",
    "    'B-': 9, 'B': 10, 'B+': 11,\n",
    "    'A-': 12, 'A': 13, 'A+': 14,\n",
    "}\n",
    "\n",
    "# On place donc les valeurs decimales associées aux notes alphabetiques grace au map dans une nouvelle colonne note_dec\n",
    "grades_df['note_dec'] = grades_df['note'].map(grade_to_num)\n",
    "\n",
    "# On transforme en note sur 20\n",
    "# Avec fonction .apply\n",
    "grades_df['note_dec'] = grades_df['note_dec'].apply(lambda x: (x / 14) * 20)\n",
    "\n",
    "# Version sans fonction, mais avec operation vectorisée\n",
    "#grades_df['note_dec'] = (grades_df['note_dec']/14)*20\n",
    "\n",
    "# Ajout d'une colonne 'result' contenant 'Réussite' si note >=10 sinon 'Echec'   \n",
    "grades_df['result'] = grades_df['note_dec'].apply(lambda x: \"Réussite\" if x >= 10 else \"Échec\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
